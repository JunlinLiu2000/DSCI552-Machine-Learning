{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wSRZOKAEMx8"
      },
      "source": [
        "cd ../data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUmOzqx4kJol"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "file_list = ['TPP.txt', 'TAM.txt','MLOE.txt', 'OKEWFSMP.txt', 'THWP.txt', 'TAMatter.txt', 'AIIMAT.txt']\n",
        "outfile = open('corpus.txt', 'w')\n",
        "for file in file_list:\n",
        "  with open(file, 'r', encoding='ascii' ,errors='ignore') as filename:\n",
        "    for line in filename:\n",
        "      outfile.write(line)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL5uZyHckeAA"
      },
      "source": [
        "## 1(c)ii"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3LOJrDckOE0",
        "outputId": "d910dc12-b254-4445-9d03-4a817a720d37"
      },
      "source": [
        "data = open('corpus.txt').read().lower()\n",
        "data = set(data)\n",
        "dic = {}\n",
        "int_dic = {}\n",
        "for i in data:\n",
        "  dic[i] = float(ord(i)/126)\n",
        "  int_dic[float(ord(i)/126)] = i\n",
        "int_dic"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.07936507936507936: '\\n',\n",
              " 0.25396825396825395: ' ',\n",
              " 0.2619047619047619: '!',\n",
              " 0.2698412698412698: '\"',\n",
              " 0.2777777777777778: '#',\n",
              " 0.2857142857142857: '$',\n",
              " 0.29365079365079366: '%',\n",
              " 0.30158730158730157: '&',\n",
              " 0.30952380952380953: \"'\",\n",
              " 0.31746031746031744: '(',\n",
              " 0.3253968253968254: ')',\n",
              " 0.3333333333333333: '*',\n",
              " 0.3412698412698413: '+',\n",
              " 0.3492063492063492: ',',\n",
              " 0.35714285714285715: '-',\n",
              " 0.36507936507936506: '.',\n",
              " 0.373015873015873: '/',\n",
              " 0.38095238095238093: '0',\n",
              " 0.3888888888888889: '1',\n",
              " 0.3968253968253968: '2',\n",
              " 0.40476190476190477: '3',\n",
              " 0.4126984126984127: '4',\n",
              " 0.42063492063492064: '5',\n",
              " 0.42857142857142855: '6',\n",
              " 0.4365079365079365: '7',\n",
              " 0.4444444444444444: '8',\n",
              " 0.4523809523809524: '9',\n",
              " 0.4603174603174603: ':',\n",
              " 0.46825396825396826: ';',\n",
              " 0.47619047619047616: '<',\n",
              " 0.48412698412698413: '=',\n",
              " 0.49206349206349204: '>',\n",
              " 0.5: '?',\n",
              " 0.7222222222222222: '[',\n",
              " 0.7301587301587301: '\\\\',\n",
              " 0.7380952380952381: ']',\n",
              " 0.746031746031746: '^',\n",
              " 0.753968253968254: '_',\n",
              " 0.7698412698412699: 'a',\n",
              " 0.7777777777777778: 'b',\n",
              " 0.7857142857142857: 'c',\n",
              " 0.7936507936507936: 'd',\n",
              " 0.8015873015873016: 'e',\n",
              " 0.8095238095238095: 'f',\n",
              " 0.8174603174603174: 'g',\n",
              " 0.8253968253968254: 'h',\n",
              " 0.8333333333333334: 'i',\n",
              " 0.8412698412698413: 'j',\n",
              " 0.8492063492063492: 'k',\n",
              " 0.8571428571428571: 'l',\n",
              " 0.8650793650793651: 'm',\n",
              " 0.873015873015873: 'n',\n",
              " 0.8809523809523809: 'o',\n",
              " 0.8888888888888888: 'p',\n",
              " 0.8968253968253969: 'q',\n",
              " 0.9047619047619048: 'r',\n",
              " 0.9126984126984127: 's',\n",
              " 0.9206349206349206: 't',\n",
              " 0.9285714285714286: 'u',\n",
              " 0.9365079365079365: 'v',\n",
              " 0.9444444444444444: 'w',\n",
              " 0.9523809523809523: 'x',\n",
              " 0.9603174603174603: 'y',\n",
              " 0.9682539682539683: 'z',\n",
              " 0.9761904761904762: '{',\n",
              " 0.9841269841269841: '|',\n",
              " 0.9920634920634921: '}',\n",
              " 1.0: '~'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egTX9LPEF9RU"
      },
      "source": [
        "tuple_list = []\n",
        "for key, value in int_dic.items():\n",
        "  tuple_list.append((key, value))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9JbWo7fkkMh"
      },
      "source": [
        "## 1(c) iii~v"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rct_5_BIkntZ"
      },
      "source": [
        "W = 100\n",
        "S = 1\n",
        "input = []\n",
        "output = []\n",
        "data = open('corpus.txt').read().lower()\n",
        "for i in range(0,len(data)-W+1):\n",
        "  sequence1 = data[i:i+W-1]\n",
        "  sequence2 = data[i+W-1]\n",
        "  list1 = []\n",
        "  for j in sequence1:\n",
        "    list1.append(dic[j])\n",
        "  input.append(list1)\n",
        "  output.append(dic[sequence2])\n",
        "\n",
        "from keras.utils import np_utils\n",
        "new_input = np.reshape(input, (len(input), 99, 1))\n",
        "new_output = np_utils.to_categorical(output)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uunYISVGksN2"
      },
      "source": [
        "## 1(c)vi~x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZKZrNPFkwBn",
        "outputId": "46114cdd-11b7-4bd1-8cec-08320af93ba7"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "LSTMmodel = Sequential()\n",
        "LSTMmodel.add(LSTM(256, input_shape = (new_input.shape[1], new_input.shape[2])))\n",
        "LSTMmodel.add(Dense(new_output.shape[1], activation='softmax'))\n",
        "LSTMmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "filepath1 = '/content/drive/MyDrive/hw7/LSTM.weights.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath = filepath1, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
        "LSTMmodel.fit(new_input, new_output, epochs=30, batch_size=512, callbacks=[checkpoint])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.6173e-04WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 277s 27ms/step - loss: 2.6173e-04\n",
            "Epoch 2/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.5948e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.5948e-05\n",
            "Epoch 3/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.3909e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.3909e-05\n",
            "Epoch 4/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.5192e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 268s 27ms/step - loss: 2.5192e-05\n",
            "Epoch 5/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.3791e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.3791e-05\n",
            "Epoch 6/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.4925e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.4925e-05\n",
            "Epoch 7/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.5127e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 270s 27ms/step - loss: 2.5127e-05\n",
            "Epoch 8/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.5159e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 270s 27ms/step - loss: 2.5159e-05\n",
            "Epoch 9/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.4547e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 270s 27ms/step - loss: 2.4547e-05\n",
            "Epoch 10/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.3971e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.3971e-05\n",
            "Epoch 11/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.3963e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.3963e-05\n",
            "Epoch 12/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.3974e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 270s 27ms/step - loss: 2.3974e-05\n",
            "Epoch 13/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.4839e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 270s 27ms/step - loss: 2.4839e-05\n",
            "Epoch 14/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.3723e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 270s 27ms/step - loss: 2.3723e-05\n",
            "Epoch 15/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.4948e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 270s 27ms/step - loss: 2.4948e-05\n",
            "Epoch 16/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.4142e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.4142e-05\n",
            "Epoch 17/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.4238e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.4238e-05\n",
            "Epoch 18/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.4566e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.4566e-05\n",
            "Epoch 19/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.4273e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 268s 27ms/step - loss: 2.4273e-05\n",
            "Epoch 20/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.4041e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.4041e-05\n",
            "Epoch 21/30\n",
            "9900/9901 [============================>.] - ETA: 0s - loss: 2.4358e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.4356e-05\n",
            "Epoch 22/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.4024e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.4024e-05\n",
            "Epoch 23/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.3984e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.3984e-05\n",
            "Epoch 24/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.4645e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.4645e-05\n",
            "Epoch 25/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.3383e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 269s 27ms/step - loss: 2.3383e-05\n",
            "Epoch 26/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.4049e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 267s 27ms/step - loss: 2.4049e-05\n",
            "Epoch 27/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.4123e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 267s 27ms/step - loss: 2.4123e-05\n",
            "Epoch 28/30\n",
            "9901/9901 [==============================] - ETA: 0s - loss: 2.4112e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 267s 27ms/step - loss: 2.4112e-05\n",
            "Epoch 29/30\n",
            "9899/9901 [============================>.] - ETA: 0s - loss: 2.4215e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 267s 27ms/step - loss: 2.4210e-05\n",
            "Epoch 30/30\n",
            "9899/9901 [============================>.] - ETA: 0s - loss: 2.4188e-05WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "9901/9901 [==============================] - 267s 27ms/step - loss: 2.4186e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b0016ead0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll44dc7u7SDB",
        "outputId": "3b285fc0-6dd2-41d3-a7da-f557501807b2"
      },
      "source": [
        "print('best set of weights in terms of loss is' ,2.3791e-05)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best set of weights in terms of loss is 2.3791e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH5R4ny61Wa1",
        "outputId": "2667ff2d-feb1-4cff-84f7-f3abbeab88e2"
      },
      "source": [
        "LSTMmodel.save(\"my_model\")\n",
        "reconstructed_model = keras.models.load_model(\"my_model\")\n",
        "\n",
        "text = 'There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.'\n",
        "text = text.lower()\n",
        "char_list = []\n",
        "for i in text[0:99]:\n",
        "  char_list.append(dic[i])\n",
        "\n",
        "predict_list = []\n",
        "for i in range(1000):\n",
        "  new_text = np.reshape(char_list, (1, len(char_list), 1))\n",
        "  predict = reconstructed_model.predict(new_text, verbose=0)\n",
        "  index = np.argmax(predict)\n",
        "  predict_list.append(tuple_list[index][1])\n",
        "\n",
        "sentence = \" \"\n",
        "for i in text[0:99]:\n",
        "  sentence += i\n",
        "for i in predict_list:\n",
        "  sentence += i\n",
        "print(sentence)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: my_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: my_model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f0b7f3a3d90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " there are those who take mental phenomena naively, just as they would physical phenomena. this schojjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\n"
          ]
        }
      ]
    }
  ]
}